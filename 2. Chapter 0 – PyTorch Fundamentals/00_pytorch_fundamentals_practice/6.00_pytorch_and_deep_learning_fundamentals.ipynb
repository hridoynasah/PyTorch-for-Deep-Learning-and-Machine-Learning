{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27781084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check Pytorch Version \n",
    "torch.__version__\n",
    "\n",
    "# nn contains all of PyTorch's building blocks for neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198233f",
   "metadata": {},
   "source": [
    "---\n",
    "- Tensors are the fundamental building block of machine learning \n",
    "- Their job is to represnt data in a numerical way\n",
    "- we can represnt image into numbers too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d710b",
   "metadata": {},
   "source": [
    "#### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0cc989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7), torch.int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saclar tensor (Zero dimension, just a number)\n",
    "scalar = torch.tensor(7)\n",
    "scalar, scalar.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f802c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7228d84d",
   "metadata": {},
   "source": [
    "- A vector is a single dimension tensor but can contain many numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed69ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7]) # count square brackets\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e2e230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78397b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape # it shows the number of elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da7f05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 4, 5]), 1, torch.Size([4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.tensor([1,2,4,5])\n",
    "v, v.ndim, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc560c9",
   "metadata": {},
   "source": [
    "- MATRIX has two dimensions (did you count the number of square brackets on the outside of one side?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40a5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix = torch.tensor([[1,2],\n",
    "                       [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb13e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " 2,\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix, Matrix.ndim, Matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc943c65",
   "metadata": {},
   "source": [
    "- Tensors are 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d652e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [3, 4, 5]],\n",
       " \n",
       "         [[1, 2, 4],\n",
       "          [3, 4, 5]]]),\n",
       " 3,\n",
       " torch.Size([2, 2, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor = torch.tensor([[[1,2,3],\n",
    "                        [3,4,5]],\n",
    "                        [[1,2,4],\n",
    "                         [3,4,5]]])\n",
    "Tensor, Tensor.ndim, Tensor.shape\n",
    "# 2 ta 2x3 Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598207ad",
   "metadata": {},
   "source": [
    "- Random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe7fc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3798, 0.7187, 0.2344, 0.0117],\n",
       "         [0.1894, 0.9834, 0.5239, 0.6645],\n",
       "         [0.7761, 0.4141, 0.7857, 0.2326]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b65f6",
   "metadata": {},
   "source": [
    "- The flexibility of torch.rand() is that we can adjust the size to be whatever we want.\n",
    "\n",
    "- For example, say you wanted a random tensor in the common image shape of [224, 224, 3] ([height, width, color_channels])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb63d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[7.6528e-01, 4.3714e-01, 4.4143e-01],\n",
       "          [6.6607e-01, 1.9373e-01, 9.5005e-01],\n",
       "          [2.5403e-01, 8.0087e-01, 6.8590e-01],\n",
       "          ...,\n",
       "          [5.1869e-01, 5.8176e-01, 1.9605e-01],\n",
       "          [4.3058e-01, 3.4157e-01, 3.1647e-01],\n",
       "          [1.9750e-01, 1.4621e-02, 3.1342e-01]],\n",
       " \n",
       "         [[3.7648e-02, 2.8228e-01, 4.6823e-01],\n",
       "          [8.9236e-01, 4.0516e-01, 7.2546e-01],\n",
       "          [6.7174e-01, 9.0021e-01, 6.0603e-01],\n",
       "          ...,\n",
       "          [3.2332e-01, 3.0071e-01, 8.7744e-01],\n",
       "          [7.3147e-04, 1.0487e-01, 4.6993e-01],\n",
       "          [2.0207e-01, 1.6551e-01, 4.8704e-01]],\n",
       " \n",
       "         [[3.1484e-01, 7.7662e-01, 3.8400e-01],\n",
       "          [4.5506e-01, 7.5635e-01, 3.2506e-01],\n",
       "          [1.2347e-01, 7.2540e-01, 2.8359e-01],\n",
       "          ...,\n",
       "          [2.7458e-01, 2.0799e-01, 4.0259e-01],\n",
       "          [6.7754e-01, 2.3043e-02, 8.2361e-01],\n",
       "          [5.7597e-01, 3.3896e-01, 7.6366e-03]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.2899e-01, 8.8925e-01, 2.1544e-01],\n",
       "          [9.6277e-01, 5.6508e-02, 2.6827e-01],\n",
       "          [5.3220e-02, 5.1078e-01, 2.6315e-01],\n",
       "          ...,\n",
       "          [6.0693e-01, 6.3087e-01, 3.9030e-01],\n",
       "          [4.1960e-02, 8.0165e-01, 1.3004e-01],\n",
       "          [5.8213e-01, 3.0645e-01, 9.5465e-01]],\n",
       " \n",
       "         [[5.5614e-01, 7.4751e-01, 7.3833e-01],\n",
       "          [4.6318e-01, 5.2175e-02, 9.0762e-01],\n",
       "          [6.2472e-01, 3.6526e-01, 7.5511e-01],\n",
       "          ...,\n",
       "          [6.6640e-01, 6.7798e-01, 1.7416e-02],\n",
       "          [3.2693e-02, 6.6670e-01, 3.5063e-02],\n",
       "          [3.2958e-01, 3.2419e-01, 2.3228e-01]],\n",
       " \n",
       "         [[3.3566e-02, 5.2716e-01, 3.2920e-01],\n",
       "          [5.4361e-03, 5.6389e-01, 1.6436e-01],\n",
       "          [9.1079e-02, 1.5693e-01, 6.2611e-01],\n",
       "          ...,\n",
       "          [6.4030e-01, 9.2728e-02, 4.3691e-01],\n",
       "          [5.6479e-01, 9.7310e-01, 8.4345e-01],\n",
       "          [4.8632e-01, 7.2143e-01, 1.2251e-01]]]),\n",
       " 3,\n",
       " torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size = (224, 224, 3))\n",
    "random_image_size_tensor, random_image_size_tensor.ndim, random_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fcf64",
   "metadata": {},
   "source": [
    "- Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6f8413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f81c3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.Size([3, 4]),\n",
       " 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size = (3,4))\n",
    "ones, ones.shape, ones.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06d942",
   "metadata": {},
   "source": [
    "- Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4eb2ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(0, 11)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a67044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44,\n",
       "        46, 48, 50])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax : arange(start, end, step)\n",
    "evens = torch.arange(10, 51, 2)\n",
    "evens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad9dba3",
   "metadata": {},
   "source": [
    "- Zeros like, Ones like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b0f5d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2144, 0.3971, 0.7090, 0.6540],\n",
       "         [0.2180, 0.6367, 0.7886, 0.3702],\n",
       "         [0.4598, 0.4719, 0.5605, 0.0785]],\n",
       "\n",
       "        [[0.8398, 0.6756, 0.1626, 0.5524],\n",
       "         [0.7390, 0.8392, 0.9147, 0.9749],\n",
       "         [0.9217, 0.0020, 0.7993, 0.4391]],\n",
       "\n",
       "        [[0.8893, 0.5015, 0.3933, 0.1623],\n",
       "         [0.1217, 0.3193, 0.7268, 0.6102],\n",
       "         [0.0226, 0.6642, 0.2615, 0.1922]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_a = torch.rand(size = (3,3,4))\n",
    "random_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c2994a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zeros like \n",
    "zeros_like = torch.zeros_like(random_a)\n",
    "zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69694adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ones like \n",
    "ones_like = torch.ones_like(random_a)\n",
    "ones_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f790d",
   "metadata": {},
   "source": [
    "- Tensors Datatypes  \n",
    "\n",
    "`torch.float16 or torch.half`, `torch.float32 or torch.float`, `torch.float64 or torch.double`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5d1482e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 9.0],\n",
    "                               dtype= torch.half)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c1296",
   "metadata": {},
   "source": [
    "- Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285aed62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three attribute (.shape, .dtype, .device)\n",
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor.shape, some_tensor.dtype, some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa6414",
   "metadata": {},
   "source": [
    "- Manipulating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c07e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorA = torch.tensor([3, 5, 8])\n",
    "tensorB = torch.tensor([7, 5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8c1b5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition \n",
    "tensorA + tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64177e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 15, 18])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorA + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccf0c2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4,  0,  6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction \n",
    "tensorA - tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cdf331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -3, -6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorB - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0860260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4286, 1.0000, 4.0000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division \n",
    "tensorA / tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "283b6a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorA // tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5551ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 25, 16])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication element wise \n",
    "tensorA * tensorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9741353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 50, 80])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorA * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e08e4",
   "metadata": {},
   "source": [
    "- Matrix Multiplication "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
