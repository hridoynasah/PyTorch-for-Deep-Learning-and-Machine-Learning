{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5c37c6",
   "metadata": {},
   "source": [
    "**NN Module of PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863aac2",
   "metadata": {},
   "source": [
    "* Building a model with One Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9359c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train  →  Linear layer (with 1 unit)  →  Sigmoid activation  →  Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2743b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define a custom model class that inherits from PyTorch's base nn.Module\n",
    "class Model_V1(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()  # Initialize parent class (nn.Module)\n",
    "\n",
    "        # Define a linear (fully connected) layer\n",
    "        # Takes 'in_features' inputs and outputs a single value\n",
    "        self.linear = nn.Linear(in_features=in_features,\n",
    "                                out_features=1)\n",
    "\n",
    "        # Define a sigmoid activation function\n",
    "        # Note: Should be nn.Sigmoid() (capital S), not nn.sigmoid()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Pass input X through the linear layer (apply weights & bias)\n",
    "        z = self.linear(X)\n",
    "\n",
    "        # Apply sigmoid activation to squash output between 0 and 1\n",
    "        y_pred = self.sigmoid(z)\n",
    "\n",
    "        # Return the predicted value\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e4963",
   "metadata": {},
   "source": [
    "- `self.linear`, `self.sigmoid` \n",
    "They’re defined in `__init__` so that the same layers/operations (`self.linear`, `self.sigmoid`) can be reused inside `forward` during every call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7efed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3905],\n",
       "        [0.4013],\n",
       "        [0.3926],\n",
       "        [0.4168],\n",
       "        [0.4572],\n",
       "        [0.4094],\n",
       "        [0.4361],\n",
       "        [0.4107],\n",
       "        [0.4612],\n",
       "        [0.3942]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dummy dataset\n",
    "X_train = torch.rand(10, 5)\n",
    "\n",
    "# Create model\n",
    "model = Model_V1(X_train.shape[1])\n",
    "\n",
    "# Call the forward pass\n",
    "# model.foward(X) -> this not recommended\n",
    "model(X_train) # Recommended by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e8bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1459, -0.1894, -0.3744, -0.0159,  0.3304]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print weights and bias\n",
    "print(f\"{model.linear.weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760237a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.1283], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{model.linear.bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9e379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1459, -0.1894, -0.3744, -0.0159,  0.3304]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1283], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00e8bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\Hridoy\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\Hridoy\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\Hridoy\\anaconda3\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc61dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    [10, 1]                   --\n",
       "├─Linear: 1-1                            [10, 1]                   6\n",
       "├─Sigmoid: 1-2                           [10, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 6\n",
       "Trainable params: 6\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary # type: ignore\n",
    "summary(model, input_size=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4022e7",
   "metadata": {},
   "source": [
    "* Building a model using 2 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define a custom model class that inherits from PyTorch's base nn.Module\n",
    "class Model_V2(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()  # Initialize parent class (nn.Module)\n",
    "\n",
    "        # Creating two hidden layer\n",
    "        self.layer1 = nn.Linear(in_features=in_features,\n",
    "                                out_features=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(in_features=3,\n",
    "                                out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        f = self.layer1(X)\n",
    "        r = self.relu(f)\n",
    "        z = self.layer2(r)\n",
    "        y_pred = self.sigmoid(z)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bfc157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4710],\n",
       "        [0.4635],\n",
       "        [0.4591],\n",
       "        [0.4763],\n",
       "        [0.4737],\n",
       "        [0.4502],\n",
       "        [0.4624],\n",
       "        [0.4700],\n",
       "        [0.4804],\n",
       "        [0.4788]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dummy dataset\n",
    "X_train = torch.rand(10, 5)\n",
    "\n",
    "# Create model\n",
    "model = Model_V2(X_train.shape[1])\n",
    "\n",
    "# Call the forward pass\n",
    "# model.foward(X) -> this not recommended\n",
    "model(X_train) # Recommended by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc74d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0795,  0.1676, -0.1040,  0.0914,  0.4159],\n",
      "        [-0.2198,  0.3457,  0.4003,  0.0244,  0.1384],\n",
      "        [-0.3484,  0.1516,  0.0427,  0.3061,  0.1286]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2297,  0.2334, -0.1421], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1296, -0.1486, -0.0779]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0164], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c32c30",
   "metadata": {},
   "source": [
    "* Using sequentail container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39687783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Define the model using Sequential\n",
    "class Model_V3(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # Sequentially stack layers and activations\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=3),  # Layer 1\n",
    "            nn.ReLU(),                                           # Activation\n",
    "            nn.Linear(in_features=3, out_features=1),            # Layer 2\n",
    "            nn.Sigmoid()                                         # Activation\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        y_pred = self.network(X)  # Pass input through the Sequential container\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02acc5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6089],\n",
       "        [0.6294],\n",
       "        [0.6556],\n",
       "        [0.6667],\n",
       "        [0.6328],\n",
       "        [0.6769],\n",
       "        [0.6121],\n",
       "        [0.5831],\n",
       "        [0.5996],\n",
       "        [0.6722]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dummy dataset\n",
    "X_train = torch.rand(10, 5)\n",
    "\n",
    "# Create model\n",
    "model = Model_V3(X_train.shape[1])\n",
    "\n",
    "# Call the forward pass\n",
    "# model.foward(X) -> this not recommended\n",
    "model(X_train) # Recommended by PyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
